{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuitive Neural Networks by Hand\n",
    "\n",
    "This notebook shows how to build a neural network by hand.  The motivation for creating _yet another_ neural network from scratch post is that I believe most get lost in the calculus and lose the concepts.  Additionally, I believe the demonstation code is often designed to be pragmatic, not illustrative.\n",
    "\n",
    "Below, we create classes to represent our neural network and then use it to fit to a simple example from the Iris dataset.\n",
    "\n",
    "* NOTE: Code is still under active development and bugs likely exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concepts\n",
    "\n",
    "Neural networks are essentially two things:\n",
    "1. A collection of layers with weights\n",
    "1. A forwards-backwards algorithm (of sorts) for optimizing those weights.\n",
    "\n",
    "The forward-backward algorithm is a common paradigm outside of neural networks and is helpful to learn about. By analogy, the forward step simply computes the current outcome probabilities.  The backwards step updates the weights used in making predictions to those that seem best at the current iteration.  This process continues (hopefully) to convergence.\n",
    "\n",
    "At prediction time, one is essentially re-computing the forward step of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"static/neural-network.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "\n",
    "EPSILON = 0.8\n",
    "\n",
    "\n",
    "def binary_loss_function(predictions, Y):\n",
    "    \"\"\"Loss function for a binary classifier\"\"\"\n",
    "    return log_loss(Y, (predictions[0] > 0.5).astype(int))\n",
    "\n",
    "\n",
    "def relu_activation(x):\n",
    "    \"\"\"Vectorized relu activation function\n",
    "    :return: 0 if x is less than 0, x otherwise.\n",
    "    \"\"\"\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def sigmoid_activation(x):\n",
    "    \"\"\"Vectorized sigmoid activation function\n",
    "    :return: sigmoid of x\n",
    "    \"\"\"\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "  \n",
    "class Model:\n",
    "    def __init__(self, data, Y, model_structure, cost_function, learning_rate):\n",
    "        self.data = data\n",
    "        self.Y = Y\n",
    "        self.model_structure = model_structure\n",
    "        self.cost_function = cost_function\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = None\n",
    "        \n",
    "    def train(self, learning_rate=0.1, num_iterations=5000):\n",
    "        self.iterations = []\n",
    "        prior_iteration = None\n",
    "        for iteration in range(num_iterations):\n",
    "            model_iteration = ModelIteration(self, self.data, self.Y, learning_rate, prior_iteration)\n",
    "            self.iterations.append(model_iteration)\n",
    "            \n",
    "            iteration_output = model_iteration.feed_forward(self.data)\n",
    "            model_iteration.propegate_backward() # update weights\n",
    "    \n",
    "            prior_iteration = model_iteration\n",
    "            \n",
    "            if iteration % 1000 == 0:\n",
    "                print(\"Completed iteration {}.  Loss: {}\".format(iteration, self.evaluate(self.data, self.Y)))\n",
    "                \n",
    "        return self.evaluate(self.data, self.Y)\n",
    "            \n",
    "    def predict(self, data=None):\n",
    "        self.assert_trained()\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "        return self.iterations[-1].predict(data)\n",
    "    \n",
    "    def evaluate(self, data=None, Y=None):\n",
    "        self.assert_trained()\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "            Y = self.Y\n",
    "        return self.iterations[-1].evaluate(data, Y)\n",
    "    \n",
    "    def assert_trained(self):\n",
    "        if self.iterations is None:\n",
    "            raise Exception(\"Must train before running `predict`.\")\n",
    "        \n",
    "    \n",
    "class ModelIteration:\n",
    "    def __init__(self, model, data, Y, learning_rate, prior_iteration=None):\n",
    "        self.model = model  # locator pattern\n",
    "        # don't store data again, just wasteful\n",
    "        self.learning_rate = learning_rate\n",
    "        self.prior_iteration = prior_iteration\n",
    "        self.layers = []\n",
    "        for layer_number, layer in enumerate(self.model.model_structure):\n",
    "            if self.prior_iteration is None: # first iteration, must initialize weights\n",
    "                if 0 == layer_number:\n",
    "                    prior_layer_size = data.shape[1]\n",
    "                else:\n",
    "                    prior_layer_size = self.layers[-1].size\n",
    "                weights = np.random.randn(layer[\"size\"], prior_layer_size)\n",
    "                betas = np.zeros((layer[\"size\"], 1))\n",
    "            else:\n",
    "                weights = self.prior_iteration.layers[layer_number].weights # backprop output\n",
    "                betas = self.prior_iteration.layers[layer_number].betas            \n",
    "           \n",
    "            layer = Layer(self, layer[\"size\"], layer[\"activation\"], weights, betas)\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "    def feed_forward(self, data):\n",
    "        prior_output = self.model.data.T\n",
    "        for layer in self.layers:\n",
    "            output = layer.apply_weights(prior_output)\n",
    "            #print(output)\n",
    "            prior_output = output\n",
    "        return output\n",
    "    \n",
    "    def predict(self, data):\n",
    "         return self.feed_forward(data)\n",
    "        \n",
    "    def evaluate(self, data=None, Y=None):\n",
    "        if data is None:\n",
    "            data = self.model.data\n",
    "            Y = self.model.Y\n",
    "        predictions = self.predict(data)\n",
    "        return self.model.cost_function(predictions, Y)\n",
    "\n",
    "    def propegate_backward(self):\n",
    "        # iterate backwards\n",
    "        for layer in self.layers[::-1]:\n",
    "            layer.update_weights(self.learning_rate)\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, model_iteration, size, activation_function, weights, betas):\n",
    "        self.model_iteration = model_iteration  # locator pattern\n",
    "        self.size = size\n",
    "        self.activation_function = activation_function\n",
    "        self.weights = weights\n",
    "        self.betas = betas\n",
    "        self.derivatives = None\n",
    "\n",
    "    def apply_weights(self, layer_input):\n",
    "        Z = np.dot(self.weights, layer_input) + self.betas\n",
    "        output = self.activation_function(Z)\n",
    "        return output\n",
    "    \n",
    "    def update_weights(self, learning_rate):\n",
    "        if self.derivatives is None:\n",
    "            self.calculate_derivatives()\n",
    "        self.weights = self.weights - learning_rate * self.derivatives\n",
    "    \n",
    "    def calculate_derivatives(self):\n",
    "        # add epsilon and substract epsilon from weights and re-run....\n",
    "        original_weights = self.weights\n",
    "        \n",
    "        flat_weights = original_weights.reshape(np.size(original_weights))\n",
    "        derivatives = []\n",
    "        for index, weight in enumerate(flat_weights):\n",
    "            epsilon_vector = np.zeros(flat_weights.shape[0])\n",
    "            epsilon_vector[index] = EPSILON\n",
    "            \n",
    "            self.weights = (flat_weights - epsilon_vector).reshape(*original_weights.shape)\n",
    "            cost1 = self.model_iteration.evaluate()\n",
    "            self.weights = (flat_weights + epsilon_vector).reshape(*original_weights.shape)\n",
    "            cost2 = self.model_iteration.evaluate()\n",
    "        \n",
    "            derivative = (cost2 - cost1) / (2 * EPSILON)\n",
    "            self.weights = original_weights\n",
    "            derivatives.append(derivative)\n",
    "            \n",
    "        self.derivatives = np.array(derivatives).reshape(*original_weights.shape)\n",
    "#         print(\"Ending Calculate Derivatives\")\n",
    "#         print(\"Costs 1 and 2: {:.2f} & {:.2f}\".format(cost1, cost2))\n",
    "#         print(self.derivatives)\n",
    "        return self.derivatives\n",
    "       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration 0.  Loss: 11.512925464970227\n",
      "Completed iteration 1000.  Loss: 9.992007221626415e-16\n",
      "Completed iteration 2000.  Loss: 9.992007221626415e-16\n",
      "Completed iteration 3000.  Loss: 9.992007221626415e-16\n",
      "Completed iteration 4000.  Loss: 9.992007221626415e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.992007221626415e-16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_x = preprocessing.scale(iris[\"data\"])\n",
    "iris_y = iris[\"target\"]\n",
    "Y2 = (iris_y == 0).astype(int)\n",
    "#Y2 = (np.random.randn(len(iris_y)) > 0.3).astype(int)\n",
    "\n",
    "structure = [{\"size\": 3, \"activation\": sigmoid_activation}, \n",
    "             {\"size\": 1, \"activation\": sigmoid_activation}]\n",
    "\n",
    "\n",
    "model = Model(iris_x, Y2, structure, binary_loss_function, 0.01)\n",
    "model.train()\n",
    "# x = model.predict(iris_x)\n",
    "# model.evaluate(x, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-4af8dee91346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miris_x2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0miris_x2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'virginica'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'species'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0miris_x2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'versicolor'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'species'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miris_x2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'setosa'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'species'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_x2 = preprocessing.scale(iris[\"data\"])\n",
    "iris_x2.loc[iris['Name']=='virginica','species']=0\n",
    "iris_x2.loc[iris['Name']=='versicolor','species']=1\n",
    "iris_x2.loc[iris['Name']=='setosa','species'] = 2\n",
    "iris_x2 = iris[iris['species']!=2]\n",
    "#Create Input and Output columns\n",
    "X2 = iris[['PetalLength', 'PetalWidth']].values.T\n",
    "Y2 = iris[['species']].values.T\n",
    "Y2 = Y2.astype('uint8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
